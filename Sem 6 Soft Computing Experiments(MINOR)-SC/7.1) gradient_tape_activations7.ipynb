{"cells":[{"cell_type":"code","execution_count":null,"id":"6620b326-4226-4e87-b52e-1ef891ae1dec","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6620b326-4226-4e87-b52e-1ef891ae1dec","executionInfo":{"status":"ok","timestamp":1744866482853,"user_tz":-330,"elapsed":22,"user":{"displayName":"Vaibhav Chavan","userId":"10537540842134536366"}},"outputId":"0a7cf550-f927-433e-fb27-416b43a31f59"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initial W_0 shape: (1, 3)\n","X shape: (2, 3)\n","Pad bias at top of input\n","[[ 1.  1.  1.]\n"," [ 1.  1. -1.]\n"," [ 0.  1.  1.]]\n","\n","EPOCH- 1 ================================================================================\n","\n","ITER- 1 --------------------------------------------------------------------------------\n","y = array([1.])\n","Input -> Output\n","Z_1 = array([1.])\n","A_1 = array([1.])\n","\n","Output -> Input\n","Error = array([0.])\n","dE_dW = array([0., 0., 0.])\n","W_0 = array([[1., 0., 1.]])\n","\n","ITER- 2 --------------------------------------------------------------------------------\n","y = array([-1.])\n","Input -> Output\n","Z_1 = array([2.])\n","A_1 = array([2.])\n","\n","Output -> Input\n","Error = array([4.5])\n","dE_dW = array([3., 3., 3.])\n","W_0 = array([[ 0.7, -0.3,  0.7]])\n","\n","ITER- 3 --------------------------------------------------------------------------------\n","y = array([-1.])\n","Input -> Output\n","Z_1 = array([1.7])\n","A_1 = array([1.7])\n","\n","Output -> Input\n","Error = array([3.645])\n","dE_dW = array([ 2.7, -2.7,  2.7])\n","W_0 = array([[ 0.43, -0.03,  0.43]])\n"]}],"source":["# import numpy as np\n","\n","# # Initial weights\n","# W_0 = np.array([[1, 0, 1]], dtype=float)\n","# print(\"Initial W_0 shape:\", W_0.shape)  # (1, 3)\n","\n","# # Targets\n","# t = np.array([[1 ,-1 ,-1]], dtype=float)\n","\n","# # Inputs\n","# X = np.array([\n","#     [1, 1, -1],\n","#     [0, 1, 1]\n","# ], dtype=float)\n","# print(\"X shape:\", X.shape)  # (2, 3)\n","\n","# # Activation function name\n","# f_1 = \"Lin\"\n","\n","# # Learning rate\n","# lr = 0.1\n","\n","# # Activation Functions\n","# def USigmoid(x, direction):\n","#     if direction == 'F':\n","#         return 1 / (1 + np.exp(-x))\n","#     else:  # derivative\n","#         fx = USigmoid(x, 'F')\n","#         return fx * (1 - fx)\n","\n","# def BSigmoid(x, direction):\n","#     if direction == 'F':\n","#         return (1 - np.exp(-x)) / (1 + np.exp(-x))\n","#     else:\n","#         fx = BSigmoid(x, 'F')\n","#         return 0.5 * (1 - fx ** 2)\n","\n","# def ReLU(x, direction):\n","#     if direction == 'F':\n","#         return np.maximum(0, x)\n","#     else:\n","#         return float(x > 0)\n","\n","# def Lin(x, direction):\n","#     if direction == 'F':\n","#         return x\n","#     else:\n","#         return 1\n","\n","# # Activation wrapper\n","# def activation(Z, fcn=\"Lin\", direction='F'):\n","#     Z = np.atleast_1d(Z)\n","#     return np.array([globals()[fcn](z, direction) for z in Z])\n","\n","# # Training loop\n","# MAX_EPOCH = 1\n","\n","# # Pad bias term to input\n","# print('Pad bias at top of input')\n","# A_0 = np.vstack((np.ones((1, X.shape[1])), X))\n","# print(A_0)\n","\n","# for ep in range(MAX_EPOCH):\n","#     print('\\nEPOCH-', ep + 1, '=' * 80)\n","#     for itr, (x, y) in enumerate(zip(A_0.T, t.T)):\n","#         print('\\nITER-', itr + 1, '-' * 80)\n","\n","#         print(f'{y = }')\n","\n","#         # Forward pass\n","#         print('Input -> Output')\n","#         Z_1 = W_0 @ x\n","#         print(f'{Z_1 = }')\n","#         A_1 = activation(Z_1, f_1)\n","#         print(f'{A_1 = }')\n","\n","#         # Backward pass\n","#         print('\\nOutput -> Input')\n","#         Error = 0.5 * (A_1 - y) ** 2\n","#         print(f'{Error = }')\n","#         dE_dW = (A_1 - y) * activation(Z_1, f_1, 'B') * x\n","#         print(f'{dE_dW = }')\n","\n","#         # Weight update\n","#         W_0 = W_0 - lr * dE_dW\n","#         print(f'{W_0 = }')\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"aY1TvEYgMnD_"},"id":"aY1TvEYgMnD_"},{"cell_type":"code","execution_count":4,"id":"f8be261f-6c0c-44e6-8d83-eca0b91b1e4d","metadata":{"id":"f8be261f-6c0c-44e6-8d83-eca0b91b1e4d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744867752101,"user_tz":-330,"elapsed":43,"user":{"displayName":"Vaibhav Chavan","userId":"10537540842134536366"}},"outputId":"f2d06999-6d48-499c-d4ec-285c71d15d43"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initial W_0 shape: (1, 3)\n","X shape: (2, 3)\n","\n","EPOCH-1 ================================================================================\n","\n","ITER-1 --------------------------------------------------------------------------------\n","Target (y): 1.00\n","Z_1 (Weighted sum): 1.0000\n","A_1 (Activated output): 1.0000\n","Error: 0.0000\n","dE_dW (Gradients): [[0. 0. 0.]]\n","Updated W_0: [[1. 0. 1.]]\n","\n","ITER-2 --------------------------------------------------------------------------------\n","Target (y): -1.00\n","Z_1 (Weighted sum): 2.0000\n","A_1 (Activated output): 2.0000\n","Error: 4.5000\n","dE_dW (Gradients): [[3. 3. 3.]]\n","Updated W_0: [[ 0.7 -0.3  0.7]]\n","\n","ITER-3 --------------------------------------------------------------------------------\n","Target (y): -1.00\n","Z_1 (Weighted sum): 1.7000\n","A_1 (Activated output): 1.7000\n","Error: 3.6450\n","dE_dW (Gradients): [[ 2.7 -2.7  2.7]]\n","Updated W_0: [[ 0.43 -0.03  0.43]]\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","\n","# Initial weights\n","W_0 = tf.Variable([[1.0, 0.0, 1.0]], dtype=tf.float32)\n","print(\"Initial W_0 shape:\", W_0.shape)\n","\n","# Targets\n","t = tf.constant([[1.0, -1.0, -1.0]], dtype=tf.float32)\n","\n","# Inputs\n","X = tf.constant([\n","    [1.0, 1.0, -1.0],\n","    [0.0, 1.0, 1.0]\n","], dtype=tf.float32)\n","print(\"X shape:\", X.shape)\n","\n","# Activation function name\n","f_1 = \"Lin\"\n","\n","# Learning rate\n","lr = 0.1\n","\n","# Activation Functions\n","def USigmoid(x):\n","    return tf.math.sigmoid(x)\n","\n","def USigmoid_deriv(x):\n","    fx = tf.math.sigmoid(x)\n","    return fx * (1 - fx)\n","\n","def BSigmoid(x):\n","    return (1 - tf.exp(-x)) / (1 + tf.exp(-x))\n","\n","def BSigmoid_deriv(x):\n","    fx = BSigmoid(x)\n","    return 0.5 * (1 - tf.square(fx))\n","\n","def ReLU(x):\n","    return tf.nn.relu(x)\n","\n","def ReLU_deriv(x):\n","    return tf.cast(x > 0, tf.float32)\n","\n","def Lin(x):\n","    return x\n","\n","def Lin_deriv(x):\n","    return tf.ones_like(x)\n","\n","# Activation function dictionary\n","activation_map = {\n","    \"USigmoid\": (USigmoid, USigmoid_deriv),\n","    \"BSigmoid\": (BSigmoid, BSigmoid_deriv),\n","    \"ReLU\": (ReLU, ReLU_deriv),\n","    \"Lin\": (Lin, Lin_deriv),\n","}\n","\n","# Select activation function and its derivative\n","activation_fn, activation_deriv = activation_map[f_1]\n","\n","# Add bias term to input (pad bias row at the top)\n","A_0 = np.vstack((np.ones((1, X.shape[1])), X))\n","A_0 = tf.constant(A_0, dtype=tf.float32)\n","\n","# Training loop\n","MAX_EPOCH = 1\n","\n","# Epoch loop\n","# Epoch loop\n","for ep in range(MAX_EPOCH):\n","    print(f\"\\nEPOCH-{ep + 1} \" + \"=\" * 80)\n","\n","    for itr, (x, y) in enumerate(zip(tf.transpose(A_0), tf.transpose(t))):\n","        print(f\"\\nITER-{itr + 1} \" + \"-\" * 80)\n","\n","        # Forward pass\n","        Z_1 = tf.matmul(W_0, tf.reshape(x, [-1, 1]))\n","        A_1 = activation_fn(Z_1)\n","\n","        print(f\"Target (y): {y.numpy()[0]:.2f}\")\n","        print(f\"Z_1 (Weighted sum): {Z_1.numpy()[0][0]:.4f}\")\n","        print(f\"A_1 (Activated output): {A_1.numpy()[0][0]:.4f}\")\n","\n","        # Error and gradient\n","        Error = 0.5 * (A_1 - y) ** 2\n","        dE_dZ = (A_1 - y) * activation_deriv(Z_1)\n","        dE_dW = tf.matmul(dE_dZ, tf.reshape(x, [1, -1]))\n","\n","        print(f\"Error: {Error.numpy()[0][0]:.4f}\")\n","        print(f\"dE_dW (Gradients): {np.round(dE_dW.numpy(), 4)}\")\n","\n","        # Update weights\n","        W_0.assign_sub(lr * dE_dW)\n","        print(f\"Updated W_0: {np.round(W_0.numpy(), 4)}\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}